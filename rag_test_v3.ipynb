{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V5E1",
      "authorship_tag": "ABX9TyPD8FOrLD7Pi8/3lyxd+1PZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gitsu11/Test-Cases-RAG/blob/rag_test_visible/rag_test_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Installing pre-reqs**"
      ],
      "metadata": {
        "id": "MDHgFWof8bNO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DvM7mqwS7EBN"
      },
      "outputs": [],
      "source": [
        "!pip -q install faiss-cpu sentence-transformers langchain langchain-community langchain-text-splitters pypdf python-docx llama-cpp-python pandas tqdm requests"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Setting up google drive and folders**"
      ],
      "metadata": {
        "id": "ZJF4Vjbg8hFe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')  # uncomment if you want persistence\n",
        "\n",
        "import os, pathlib\n",
        "BASE_DIR = \"/content/drive/MyDrive/Colab\"\n",
        "DATA_DIR = f\"{BASE_DIR}/dataset_raw\"   # raw zips/files\n",
        "DOCS_DIR = f\"{BASE_DIR}/docs\"          # normalized text\n",
        "OUT_DIR  = f\"{BASE_DIR}/rag_outputs\"   # indices, exports, model\n",
        "for d in (DATA_DIR, DOCS_DIR, OUT_DIR): pathlib.Path(d).mkdir(parents=True, exist_ok=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MuOh9ma7ccl",
        "outputId": "8f46749b-0800-4392-d6d3-b47797aaefc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Getting data from zenodo**"
      ],
      "metadata": {
        "id": "eWKw-Bz58o4_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests, os, json, re, shutil, zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "ZENODO_REC_ID = \"13880060\"  # Requirements data sets (user stories)\n",
        "api_url = f\"https://zenodo.org/api/records/{ZENODO_REC_ID}\"\n",
        "rec = requests.get(api_url, timeout=60).json()\n",
        "\n",
        "files = rec.get(\"files\", []) or rec.get(\"metadata\", {}).get(\"related_identifiers\", [])  # fallback\n",
        "downloaded = []\n",
        "\n",
        "if \"files\" in rec:\n",
        "    for f in rec[\"files\"]:\n",
        "        url = f[\"links\"][\"self\"]\n",
        "        name = f[\"key\"]\n",
        "        dest = Path(DATA_DIR)/name\n",
        "        if not dest.exists():\n",
        "            with requests.get(url, stream=True, timeout=120) as r:\n",
        "                r.raise_for_status()\n",
        "                with open(dest, \"wb\") as fh:\n",
        "                    shutil.copyfileobj(r.raw, fh)\n",
        "        downloaded.append(str(dest))\n",
        "else:\n",
        "    print(\"Could not find file list in record JSON; open the Zenodo page and download manually.\")\n",
        "\n",
        "print(f\"Downloaded {len(downloaded)} files\")\n",
        "downloaded[:8]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUDbmcLB8KmV",
        "outputId": "112118f6-5b97-4e1c-e958-fe830a046c2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded 22 files\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/Colab/dataset_raw/g16-mis.txt',\n",
              " '/content/drive/MyDrive/Colab/dataset_raw/g21-badcamp.txt',\n",
              " '/content/drive/MyDrive/Colab/dataset_raw/g17-cask.txt',\n",
              " '/content/drive/MyDrive/Colab/dataset_raw/g10-scrumalliance.txt',\n",
              " '/content/drive/MyDrive/Colab/dataset_raw/g26-racdam.txt',\n",
              " '/content/drive/MyDrive/Colab/dataset_raw/g13-planningpoker.txt',\n",
              " '/content/drive/MyDrive/Colab/dataset_raw/g12-camperplus.txt',\n",
              " '/content/drive/MyDrive/Colab/dataset_raw/g19-alfred.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for p in list(Path(DATA_DIR).glob(\"*.zip\")):\n",
        "    with zipfile.ZipFile(p, 'r') as zf:\n",
        "        zf.extractall(DATA_DIR)\n",
        "    print(\"Extracted:\", p.name)"
      ],
      "metadata": {
        "id": "LbUCzLvM8N8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gzip, shutil\n",
        "from pathlib import Path\n",
        "\n",
        "RAW_DIR      = \"/content/drive/MyDrive/Colab/dataset_raw\"   # your raw data folder\n",
        "EXTRACT_DIR  = \"/content/drive/MyDrive/Colab/extracted_raw\" # new folder for decompressed text\n",
        "\n",
        "Path(EXTRACT_DIR).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def is_gzip_sig(path):\n",
        "    with open(path, \"rb\") as f:\n",
        "        return f.read(3) == b\"\\x1f\\x8b\\x08\"  # gzip magic number\n",
        "\n",
        "decompressed_files = []\n",
        "\n",
        "for p in Path(RAW_DIR).rglob(\"*\"):\n",
        "    if not p.is_file():\n",
        "        continue\n",
        "    # check extension OR signature\n",
        "    if p.suffix.lower() == \".gz\" or is_gzip_sig(str(p)):\n",
        "        out_name = p.stem  # remove .gz extension\n",
        "        out_path = Path(EXTRACT_DIR) / (out_name + \".txt\")\n",
        "\n",
        "        try:\n",
        "            with gzip.open(p, \"rb\") as f_in, open(out_path, \"wb\") as f_out:\n",
        "                shutil.copyfileobj(f_in, f_out)\n",
        "            decompressed_files.append(out_path)\n",
        "            print(f\"✅ Decompressed: {p.name} → {out_path.name}\")\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Failed on {p.name}: {e}\")\n",
        "\n",
        "print(f\"\\nTotal decompressed: {len(decompressed_files)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kcrr476iagZ6",
        "outputId": "bd2bdaf5-3a3b-4d7d-991f-0dbd5ba2d031"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Decompressed: g16-mis.txt → g16-mis.txt\n",
            "✅ Decompressed: g21-badcamp.txt → g21-badcamp.txt\n",
            "✅ Decompressed: g17-cask.txt → g17-cask.txt\n",
            "✅ Decompressed: g10-scrumalliance.txt → g10-scrumalliance.txt\n",
            "✅ Decompressed: g26-racdam.txt → g26-racdam.txt\n",
            "✅ Decompressed: g13-planningpoker.txt → g13-planningpoker.txt\n",
            "✅ Decompressed: g12-camperplus.txt → g12-camperplus.txt\n",
            "✅ Decompressed: g19-alfred.txt → g19-alfred.txt\n",
            "✅ Decompressed: g08-frictionless.txt → g08-frictionless.txt\n",
            "✅ Decompressed: g22-rdadmp.txt → g22-rdadmp.txt\n",
            "✅ Decompressed: g25-duraspace.txt → g25-duraspace.txt\n",
            "✅ Decompressed: g27-culrepo.txt → g27-culrepo.txt\n",
            "✅ Decompressed: g24-unibath.txt → g24-unibath.txt\n",
            "✅ Decompressed: g28-zooniverse.txt → g28-zooniverse.txt\n",
            "✅ Decompressed: g02-federalspending.txt → g02-federalspending.txt\n",
            "✅ Decompressed: g03-loudoun.txt → g03-loudoun.txt\n",
            "✅ Decompressed: g14-datahub.txt → g14-datahub.txt\n",
            "✅ Decompressed: g18-neurohub.txt → g18-neurohub.txt\n",
            "✅ Decompressed: g11-nsf.txt → g11-nsf.txt\n",
            "✅ Decompressed: g23-archivesspace.txt → g23-archivesspace.txt\n",
            "✅ Decompressed: g04-recycling.txt → g04-recycling.txt\n",
            "✅ Decompressed: g05-openspending.txt → g05-openspending.txt\n",
            "\n",
            "Total decompressed: 22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Normalize everything to plain text**"
      ],
      "metadata": {
        "id": "xl6OeA5_-J0_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re, glob\n",
        "from pypdf import PdfReader\n",
        "from docx import Document\n",
        "\n",
        "def file_to_text(path):\n",
        "    p = path.lower()\n",
        "    if p.endswith(\".pdf\"):\n",
        "        try:\n",
        "            pages = []\n",
        "            reader = PdfReader(path)\n",
        "            for i, pg in enumerate(reader.pages, start=1):\n",
        "                t = pg.extract_text() or \"\"\n",
        "                pages.append(f\"[PAGE {i}] {t}\")\n",
        "            return \"\\n\".join(pages)\n",
        "        except: return \"\"\n",
        "    if p.endswith(\".docx\"):\n",
        "        try:\n",
        "            doc = Document(path)\n",
        "            return \"\\n\".join(p.text for p in doc.paragraphs)\n",
        "        except: return \"\"\n",
        "    if any(p.endswith(ext) for ext in (\".txt\",\".md\",\".rst\",\".csv\")):\n",
        "        try:\n",
        "            with open(path, \"r\", errors=\"ignore\") as f: return f.read()\n",
        "        except: return \"\"\n",
        "    return \"\"  # unsupported\n",
        "\n",
        "def clean_text(s):\n",
        "    s = s.replace(\"\\x00\",\" \")\n",
        "    s = re.sub(r\"[ \\t]+\",\" \", s)\n",
        "    s = re.sub(r\"\\n{3,}\",\"\\n\\n\", s)\n",
        "    return s.strip()\n",
        "\n",
        "import os, pathlib\n",
        "count=0\n",
        "for root, _, files in os.walk(EXTRACT_DIR):\n",
        "    for fn in files:\n",
        "        src = os.path.join(root, fn)\n",
        "        txt = clean_text(file_to_text(src))\n",
        "        if txt and len(txt) > 50:\n",
        "            out = f\"{DOCS_DIR}/{pathlib.Path(fn).stem}.txt\"\n",
        "            with open(out, \"w\") as f: f.write(txt)\n",
        "            count += 1\n",
        "print(\"Normalized text files:\", count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9QhSGVa8VvM",
        "outputId": "5547524e-b852-40bf-ebb2-624fb1b15643"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized text files: 22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Chunking, Embedding, FAISS**"
      ],
      "metadata": {
        "id": "iWivQ2IU-TZM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np, faiss, pickle, glob, os\n",
        "\n",
        "# Load normalized docs\n",
        "docs = []\n",
        "for fp in sorted(glob.glob(f\"{DOCS_DIR}/*.txt\")):\n",
        "    with open(fp, \"r\", errors=\"ignore\") as f:\n",
        "        docs.append({\"source\": os.path.basename(fp), \"text\": f.read()})\n",
        "print(\"Docs:\", len(docs))\n",
        "\n",
        "# Chunk\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1200, chunk_overlap=150,\n",
        "    separators=[\"\\n## \",\"\\n# \",\"\\n\\n\",\"\\n\",\" \",\"\"]\n",
        ")\n",
        "chunks = []\n",
        "for d in docs:\n",
        "    for ch in splitter.split_text(d[\"text\"]):\n",
        "        chunks.append({\"source\": d[\"source\"], \"text\": ch})\n",
        "print(\"Chunks:\", len(chunks))\n",
        "\n",
        "# Embeddings + FAISS (cosine via normalized IP)\n",
        "EMB_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "embed_model = SentenceTransformer(EMB_NAME)\n",
        "\n",
        "B=128; vecs=[]\n",
        "texts = [c[\"text\"] for c in chunks]\n",
        "for i in range(0, len(texts), B):\n",
        "    vecs.append(embed_model.encode(texts[i:i+B], convert_to_numpy=True, normalize_embeddings=True))\n",
        "vecs = np.vstack(vecs).astype(\"float32\")\n",
        "\n",
        "index = faiss.IndexFlatIP(vecs.shape[1])\n",
        "index.add(vecs)\n",
        "\n",
        "# Persist\n",
        "with open(f\"{OUT_DIR}/chunks.pkl\",\"wb\") as f: pickle.dump(chunks,f)\n",
        "faiss.write_index(index, f\"{OUT_DIR}/faiss.index\")\n",
        "with open(f\"{OUT_DIR}/emb_model.txt\",\"w\") as f: f.write(EMB_NAME)\n",
        "print(\"Index built.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWgmHe5l-WFv",
        "outputId": "290e3934-51d5-4e44-a799-03d046b53dab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Docs: 22\n",
            "Chunks: 216\n",
            "Index built.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Retriever helper**"
      ],
      "metadata": {
        "id": "3b30Jntc-zjP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve(query, k=8):\n",
        "    q = embed_model.encode([query], convert_to_numpy=True, normalize_embeddings=True).astype(\"float32\")\n",
        "    D, I = index.search(q, k)\n",
        "    hits=[]\n",
        "    for rank,(idx,score) in enumerate(zip(I[0],D[0]), start=1):\n",
        "        hits.append({\"rank\":rank,\"score\":float(score),\"source\":chunks[idx][\"source\"],\"text\":chunks[idx][\"text\"]})\n",
        "    return hits"
      ],
      "metadata": {
        "id": "ZrQIFCQl_A8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Local LLM via llama_cpp**\n"
      ],
      "metadata": {
        "id": "xGd8O-gB_C0r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, subprocess, pathlib\n",
        "\n",
        "MODEL_URL = \"https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.2-GGUF/resolve/main/mistral-7b-instruct-v0.2.Q4_K_M.gguf\"\n",
        "MODEL_PATH = f\"{OUT_DIR}/mistral-7b-instruct.Q4_K_M.gguf\"\n",
        "if not os.path.exists(MODEL_PATH):\n",
        "    !wget -q -O \"$MODEL_PATH\" \"$MODEL_URL\"\n",
        "\n",
        "from llama_cpp import Llama\n",
        "llm = Llama(model_path=MODEL_PATH, n_ctx=8192, n_threads=8, n_gpu_layers=2, temperature=0.2)\n",
        "\n",
        "def chat_local(messages, max_tokens=1024, temperature=0.2):\n",
        "    out = llm.create_chat_completion(messages=messages, temperature=temperature, max_tokens=max_tokens)\n",
        "    return out[\"choices\"][0][\"message\"][\"content\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckMXBykx_IF2",
        "outputId": "42f36964-826d-4d60-f0dc-017c5a42a554"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_model_loader: loaded meta data with 24 key-value pairs and 291 tensors from /content/drive/MyDrive/Colab/rag_outputs/mistral-7b-instruct.Q4_K_M.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = mistralai_mistral-7b-instruct-v0.2\n",
            "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
            "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
            "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 1000000.000000\n",
            "llama_model_loader: - kv  11:                          general.file_type u32              = 15\n",
            "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
            "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  19:            tokenizer.ggml.padding_token_id u32              = 0\n",
            "llama_model_loader: - kv  20:               tokenizer.ggml.add_bos_token bool             = true\n",
            "llama_model_loader: - kv  21:               tokenizer.ggml.add_eos_token bool             = false\n",
            "llama_model_loader: - kv  22:                    tokenizer.chat_template str              = {{ bos_token }}{% for message in mess...\n",
            "llama_model_loader: - kv  23:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type q4_K:  193 tensors\n",
            "llama_model_loader: - type q6_K:   33 tensors\n",
            "print_info: file format = GGUF V3 (latest)\n",
            "print_info: file type   = Q4_K - Medium\n",
            "print_info: file size   = 4.07 GiB (4.83 BPW) \n",
            "init_tokenizer: initializing tokenizer for type 1\n",
            "load: control token:      2 '</s>' is not marked as EOG\n",
            "load: control token:      1 '<s>' is not marked as EOG\n",
            "load: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect\n",
            "load: printing all EOG tokens:\n",
            "load:   - 2 ('</s>')\n",
            "load: special tokens cache size = 3\n",
            "load: token to piece cache size = 0.1637 MB\n",
            "print_info: arch             = llama\n",
            "print_info: vocab_only       = 0\n",
            "print_info: n_ctx_train      = 32768\n",
            "print_info: n_embd           = 4096\n",
            "print_info: n_layer          = 32\n",
            "print_info: n_head           = 32\n",
            "print_info: n_head_kv        = 8\n",
            "print_info: n_rot            = 128\n",
            "print_info: n_swa            = 0\n",
            "print_info: is_swa_any       = 0\n",
            "print_info: n_embd_head_k    = 128\n",
            "print_info: n_embd_head_v    = 128\n",
            "print_info: n_gqa            = 4\n",
            "print_info: n_embd_k_gqa     = 1024\n",
            "print_info: n_embd_v_gqa     = 1024\n",
            "print_info: f_norm_eps       = 0.0e+00\n",
            "print_info: f_norm_rms_eps   = 1.0e-05\n",
            "print_info: f_clamp_kqv      = 0.0e+00\n",
            "print_info: f_max_alibi_bias = 0.0e+00\n",
            "print_info: f_logit_scale    = 0.0e+00\n",
            "print_info: f_attn_scale     = 0.0e+00\n",
            "print_info: n_ff             = 14336\n",
            "print_info: n_expert         = 0\n",
            "print_info: n_expert_used    = 0\n",
            "print_info: causal attn      = 1\n",
            "print_info: pooling type     = 0\n",
            "print_info: rope type        = 0\n",
            "print_info: rope scaling     = linear\n",
            "print_info: freq_base_train  = 1000000.0\n",
            "print_info: freq_scale_train = 1\n",
            "print_info: n_ctx_orig_yarn  = 32768\n",
            "print_info: rope_finetuned   = unknown\n",
            "print_info: model type       = 7B\n",
            "print_info: model params     = 7.24 B\n",
            "print_info: general.name     = mistralai_mistral-7b-instruct-v0.2\n",
            "print_info: vocab type       = SPM\n",
            "print_info: n_vocab          = 32000\n",
            "print_info: n_merges         = 0\n",
            "print_info: BOS token        = 1 '<s>'\n",
            "print_info: EOS token        = 2 '</s>'\n",
            "print_info: UNK token        = 0 '<unk>'\n",
            "print_info: PAD token        = 0 '<unk>'\n",
            "print_info: LF token         = 13 '<0x0A>'\n",
            "print_info: EOG token        = 2 '</s>'\n",
            "print_info: max token length = 48\n",
            "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
            "load_tensors: layer   0 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   1 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   2 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   3 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   4 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   5 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   6 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   7 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   8 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   9 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  10 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  11 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  12 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  13 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  14 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  15 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  16 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  17 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  18 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  19 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  20 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  21 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  22 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  23 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  24 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  25 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  26 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  27 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  28 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  29 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  30 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  31 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  32 assigned to device CPU, is_swa = 0\n",
            "load_tensors: tensor 'token_embd.weight' (q4_K) (and 98 others) cannot be used with preferred buffer type CPU_REPACK, using CPU instead\n",
            "load_tensors:   CPU_REPACK model buffer size =  3204.00 MiB\n",
            "load_tensors:   CPU_Mapped model buffer size =  4165.37 MiB\n",
            "repack: repack tensor blk.0.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.0.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.0.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.0.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.0.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.1.attn_q.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.1.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.1.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.1.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.1.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.2.attn_q.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.2.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.2.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.2.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.2.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.3.attn_q.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.3.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.3.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.3.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.3.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.4.attn_q.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.4.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.4.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.4.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.4.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.4.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.4.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.5.attn_q.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.5.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.5.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.5.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.5.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.5.ffn_down.weight with q4_K_8x8\n",
            "repack: repack tensor blk.5.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.6.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.6.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.6.attn_output.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.6.ffn_gate.weight with q4_K_8x8\n",
            "repack: repack tensor blk.6.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.7.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.7.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.7.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.7.attn_output.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.7.ffn_gate.weight with q4_K_8x8\n",
            "repack: repack tensor blk.7.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.7.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.8.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.8.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.8.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.8.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.8.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.8.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.8.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.9.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.9.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.9.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.9.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.9.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.10.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.10.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.10.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.10.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.10.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.10.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.10.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.11.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.11.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.11.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.11.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.11.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.11.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.11.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.12.attn_q.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.12.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.12.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.12.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.12.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.13.attn_q.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.13.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.13.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.13.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.13.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.13.ffn_down.weight with q4_K_8x8\n",
            "repack: repack tensor blk.13.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.14.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.14.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.14.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.14.attn_output.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.14.ffn_gate.weight with q4_K_8x8\n",
            "repack: repack tensor blk.14.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.14.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.15.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.15.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.15.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.15.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.15.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.16.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.16.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.16.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.16.attn_output.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.16.ffn_gate.weight with q4_K_8x8\n",
            "repack: repack tensor blk.16.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.16.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.17.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.17.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.17.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.17.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.17.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.17.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.17.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.18.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.18.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.18.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.18.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.18.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.19.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.19.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.19.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.19.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.19.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.19.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.19.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.20.attn_q.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.20.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.20.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.20.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.20.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.20.ffn_down.weight with q4_K_8x8\n",
            "repack: repack tensor blk.20.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.21.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.21.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.21.attn_output.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.21.ffn_gate.weight with q4_K_8x8\n",
            "repack: repack tensor blk.21.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.22.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.22.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.22.attn_v.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.22.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.22.ffn_gate.weight with q4_K_8x8\n",
            "repack: repack tensor blk.22.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.22.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.23.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.23.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.23.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.23.attn_output.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.23.ffn_gate.weight with q4_K_8x8\n",
            "repack: repack tensor blk.23.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.23.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.24.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.24.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.24.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.24.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.24.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.25.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.25.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.25.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.25.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.25.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.25.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.25.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.26.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.26.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.26.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.26.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.26.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.26.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.26.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.27.attn_q.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.27.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.27.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.27.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.27.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.28.attn_q.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.28.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.28.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.28.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.28.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.29.attn_q.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.29.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.29.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.29.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.29.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.30.attn_q.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.30.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.30.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.30.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.30.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.31.attn_q.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.31.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.31.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.31.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.31.ffn_up.weight with q4_K_8x8\n",
            "...................\n",
            "llama_context: constructing llama_context\n",
            "llama_context: n_seq_max     = 1\n",
            "llama_context: n_ctx         = 8192\n",
            "llama_context: n_ctx_per_seq = 8192\n",
            "llama_context: n_batch       = 512\n",
            "llama_context: n_ubatch      = 512\n",
            "llama_context: causal_attn   = 1\n",
            "llama_context: flash_attn    = 0\n",
            "llama_context: kv_unified    = false\n",
            "llama_context: freq_base     = 1000000.0\n",
            "llama_context: freq_scale    = 1\n",
            "llama_context: n_ctx_per_seq (8192) < n_ctx_train (32768) -- the full capacity of the model will not be utilized\n",
            "set_abort_callback: call\n",
            "llama_context:        CPU  output buffer size =     0.12 MiB\n",
            "create_memory: n_ctx = 8192 (padded)\n",
            "llama_kv_cache_unified: layer   0: dev = CPU\n",
            "llama_kv_cache_unified: layer   1: dev = CPU\n",
            "llama_kv_cache_unified: layer   2: dev = CPU\n",
            "llama_kv_cache_unified: layer   3: dev = CPU\n",
            "llama_kv_cache_unified: layer   4: dev = CPU\n",
            "llama_kv_cache_unified: layer   5: dev = CPU\n",
            "llama_kv_cache_unified: layer   6: dev = CPU\n",
            "llama_kv_cache_unified: layer   7: dev = CPU\n",
            "llama_kv_cache_unified: layer   8: dev = CPU\n",
            "llama_kv_cache_unified: layer   9: dev = CPU\n",
            "llama_kv_cache_unified: layer  10: dev = CPU\n",
            "llama_kv_cache_unified: layer  11: dev = CPU\n",
            "llama_kv_cache_unified: layer  12: dev = CPU\n",
            "llama_kv_cache_unified: layer  13: dev = CPU\n",
            "llama_kv_cache_unified: layer  14: dev = CPU\n",
            "llama_kv_cache_unified: layer  15: dev = CPU\n",
            "llama_kv_cache_unified: layer  16: dev = CPU\n",
            "llama_kv_cache_unified: layer  17: dev = CPU\n",
            "llama_kv_cache_unified: layer  18: dev = CPU\n",
            "llama_kv_cache_unified: layer  19: dev = CPU\n",
            "llama_kv_cache_unified: layer  20: dev = CPU\n",
            "llama_kv_cache_unified: layer  21: dev = CPU\n",
            "llama_kv_cache_unified: layer  22: dev = CPU\n",
            "llama_kv_cache_unified: layer  23: dev = CPU\n",
            "llama_kv_cache_unified: layer  24: dev = CPU\n",
            "llama_kv_cache_unified: layer  25: dev = CPU\n",
            "llama_kv_cache_unified: layer  26: dev = CPU\n",
            "llama_kv_cache_unified: layer  27: dev = CPU\n",
            "llama_kv_cache_unified: layer  28: dev = CPU\n",
            "llama_kv_cache_unified: layer  29: dev = CPU\n",
            "llama_kv_cache_unified: layer  30: dev = CPU\n",
            "llama_kv_cache_unified: layer  31: dev = CPU\n",
            "llama_kv_cache_unified:        CPU KV buffer size =  1024.00 MiB\n",
            "llama_kv_cache_unified: size = 1024.00 MiB (  8192 cells,  32 layers,  1/1 seqs), K (f16):  512.00 MiB, V (f16):  512.00 MiB\n",
            "llama_context: enumerating backends\n",
            "llama_context: backend_ptrs.size() = 1\n",
            "llama_context: max_nodes = 2328\n",
            "llama_context: worst-case: n_tokens = 512, n_seqs = 1, n_outputs = 0\n",
            "graph_reserve: reserving a graph for ubatch with n_tokens =  512, n_seqs =  1, n_outputs =  512\n",
            "graph_reserve: reserving a graph for ubatch with n_tokens =    1, n_seqs =  1, n_outputs =    1\n",
            "graph_reserve: reserving a graph for ubatch with n_tokens =  512, n_seqs =  1, n_outputs =  512\n",
            "llama_context:        CPU compute buffer size =   564.01 MiB\n",
            "llama_context: graph nodes  = 1126\n",
            "llama_context: graph splits = 1\n",
            "CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | LLAMAFILE = 1 | OPENMP = 1 | REPACK = 1 | \n",
            "Model metadata: {'tokenizer.chat_template': \"{{ bos_token }}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if message['role'] == 'user' %}{{ '[INST] ' + message['content'] + ' [/INST]' }}{% elif message['role'] == 'assistant' %}{{ message['content'] + eos_token}}{% else %}{{ raise_exception('Only user and assistant roles are supported!') }}{% endif %}{% endfor %}\", 'tokenizer.ggml.add_eos_token': 'false', 'tokenizer.ggml.padding_token_id': '0', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.rope.freq_base': '1000000.000000', 'llama.context_length': '32768', 'general.name': 'mistralai_mistral-7b-instruct-v0.2', 'tokenizer.ggml.add_bos_token': 'true', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.dimension_count': '128', 'tokenizer.ggml.bos_token_id': '1', 'llama.attention.head_count': '32', 'llama.block_count': '32', 'llama.attention.head_count_kv': '8', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '15'}\n",
            "Available chat formats from metadata: chat_template.default\n",
            "Guessed chat format: mistral-instruct\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Prompt and RAG generation**"
      ],
      "metadata": {
        "id": "rhZ_oZU0_wf_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TESTCASE_SYSTEM = \"\"\"You are a senior QA engineer. Generate rigorous, unambiguous test cases\n",
        "based ONLY on the provided context snippets. If context is missing details, list assumptions and gaps.\"\"\"\n",
        "\n",
        "TESTCASE_USER_TEMPLATE = \"\"\"Context (RAG snippets):\n",
        "---\n",
        "{context}\n",
        "---\n",
        "Task: Generate test cases for the scope: \"{scope}\".\n",
        "If acceptance criteria (AC) appear in the context, map each test to at least one AC id/phrase.\n",
        "\n",
        "Output (Markdown):\n",
        "- Feature: <name>\n",
        "- Scope: <scope>\n",
        "- Assumptions/Notes: <gaps or clarifications needed>\n",
        "- Test Cases (table):\n",
        "  | ID | Title | Type (pos/neg/edge) | Pre-Conditions | Steps | Expected Result | Priority (H/M/L) | MapsTo (AC id/phrase) |\n",
        "After the table:\n",
        "- Coverage: bullets of ACs covered and any missing ACs\n",
        "- Additional Negative/Edge Ideas: bullets\n",
        "\"\"\"\n",
        "\n",
        "def make_context(hits, max_chars=1000):\n",
        "    blocks=[]\n",
        "    for h in hits:\n",
        "        t = h[\"text\"].strip()\n",
        "        if len(t) > max_chars: t = t[:max_chars] + \"...\"\n",
        "        blocks.append(f\"[{h['source']} • score={h['score']:.2f}]\\n{t}\")\n",
        "    return \"\\n\\n\".join(blocks)\n",
        "\n",
        "def generate_test_cases(scope_query, k=8, use=\"local\"):\n",
        "    hits = retrieve(scope_query, k=k)\n",
        "    ctx = make_context(hits)\n",
        "    messages = [\n",
        "        {\"role\":\"system\",\"content\":TESTCASE_SYSTEM},\n",
        "        {\"role\":\"user\",\"content\":TESTCASE_USER_TEMPLATE.format(context=ctx, scope=scope_query)}\n",
        "    ]\n",
        "    out = chat_local(messages)  # or chat_api(messages)\n",
        "    return out, hits"
      ],
      "metadata": {
        "id": "znlbVdf6_7Pf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining function to save model outputs to drive."
      ],
      "metadata": {
        "id": "EpFovSG7gHLb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, time, re\n",
        "import pandas as pd\n",
        "\n",
        "def parse_markdown_table(md_text: str):\n",
        "    \"\"\"\n",
        "    Extracts the first Markdown table from LLM output and returns as DataFrame.\n",
        "    Assumes '|' separated table rows with a header line.\n",
        "    \"\"\"\n",
        "    lines = [ln.strip() for ln in md_text.splitlines() if ln.strip().startswith(\"|\")]\n",
        "    if not lines:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # Remove markdown alignment row (| --- | --- | etc.)\n",
        "    table_lines = [ln for ln in lines if not re.match(r'^\\|\\s*:?-+:?\\s*\\|', ln)]\n",
        "    rows = [[c.strip() for c in ln.strip(\"|\").split(\"|\")] for ln in table_lines]\n",
        "\n",
        "    if len(rows) < 2:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    header, body = rows[0], rows[1:]\n",
        "    return pd.DataFrame(body, columns=header)\n",
        "\n",
        "def generate_and_save(scope_query, k=8, use=\"local\"):\n",
        "    # Run your existing generator\n",
        "    md_text, evidence = generate_test_cases(scope_query, k=k, use=use)\n",
        "\n",
        "    # Timestamped filenames\n",
        "    ts = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "    base = scope_query.strip().replace(\" \", \"_\")[:50]\n",
        "\n",
        "    md_path = os.path.join(OUT_DIR, f\"{base}_{ts}.md\")\n",
        "    ev_path = os.path.join(OUT_DIR, f\"{base}_{ts}_evidence.txt\")\n",
        "    csv_path = os.path.join(OUT_DIR, f\"{base}_{ts}.csv\")\n",
        "\n",
        "    # Save markdown\n",
        "    with open(md_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(md_text)\n",
        "\n",
        "    # Save evidence\n",
        "    with open(ev_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        for h in evidence:\n",
        "            f.write(f\"[{h['source']} • score={h['score']:.2f}]\\n{h['text']}\\n\\n\")\n",
        "\n",
        "    # Parse table → CSV\n",
        "    df = parse_markdown_table(md_text)\n",
        "    if not df.empty:\n",
        "        df.to_csv(csv_path, index=False)\n",
        "        print(f\"✅ Saved CSV with {len(df)} rows: {csv_path}\")\n",
        "    else:\n",
        "        print(\"⚠️ No markdown table parsed, skipping CSV export.\")\n",
        "\n",
        "    print(f\"✅ Saved outputs:\\n- {md_path}\\n- {ev_path}\")\n",
        "    return md_text, evidence"
      ],
      "metadata": {
        "id": "yv9GQmeechEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#trying it\n",
        "md_text, evidence = generate_test_cases(\n",
        "    \"User registration: email verification, strong password policy, duplicate email handling\",\n",
        "    k=10, use=\"local\"\n",
        ")\n",
        "print(md_text[:1500])"
      ],
      "metadata": {
        "id": "kZDvKTLEAP09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e0ef1e0-81c8-4faf-bd08-55b5e1817897"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =   48945.95 ms\n",
            "llama_perf_context_print: prompt eval time =   48945.47 ms /  2605 tokens (   18.79 ms per token,    53.22 tokens per second)\n",
            "llama_perf_context_print:        eval time =   76518.28 ms /  1023 runs   (   74.80 ms per token,    13.37 tokens per second)\n",
            "llama_perf_context_print:       total time =  126427.37 ms /  3628 tokens\n",
            "llama_perf_context_print:    graphs reused =        990\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " - Feature: User Registration\n",
            "- Scope: Email verification, strong password policy, duplicate email handling\n",
            "- Assumptions/Notes: The system allows users to register with a valid email address and a strong password.\n",
            "\n",
            "- Test Cases (table):\n",
            "  | ID | Title | Type (pos/neg/edge) | Pre-Conditions | Steps | Expected Result | Priority (H/M/L) | MapsTo (AC id/phrase) |\n",
            "  | 1 | Valid Email Registration | Positive | None | User enters a valid email address and a strong password during registration | User is successfully registered and receives a verification email | High | As a user, I want to register with a valid email address (g21-badcamp.txt, g10-scrumalliance.txt, g13-planningpoker.txt, g10-scrumalliance.txt, g03-loudoun.txt, g27-culrepo.txt, g04-recycling.txt, g26-racdam.txt, g02-federalspending.txt, g12-camperplus.txt) |\n",
            "  | 2 | Invalid Email Registration | Negative | None | User enters an invalid email address during registration | Registration fails with an error message | Medium | As a user, I want to enter a valid email address (g21-badcamp.txt, g10-scrumalliance.txt, g13-planningpoker.txt, g10-scrumalliance.txt, g03-loudoun.txt, g27-culrepo.txt, g04-recycling.txt, g26-racdam.txt, g02-federalspending.txt, g12-camperplus.txt) |\n",
            "  | 3 | Weak Password Registration | Negative | None | User enters a weak password during registration | Registration fails with an error message | Medium | As a user, I want to enter a strong password (g21-badcamp.txt, g10-scrumalliance.txt, g13-planni\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(evidence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNSb5jXfO65L",
        "outputId": "609cc56e-5b7d-460e-c12d-83b63499918d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'rank': 1, 'score': 0.28261128067970276, 'source': 'g21-badcamp.txt', 'text': \"As a anonymoususer, I want to view a list of sponsors, so that I can thank all the awesome sponsors.\\nAs a anonymoususer, I want to view a list of user profiles, so that I know who is attending the conference.\\nAs a trainingcoordinator, I want to email all the trainers at once from the website for info and updates, so that It is easier to use.\\nAs a attendee, I want to have a very clear map where the buildings and rooms are, so that I can make it to class on time.\\nAs a trainer, I want to edit my training node myself, so that the training coordinators don't have to and links to slides.\\nAs a trainee, I want to limit to one registration per day per authenticated user, so that we don't have duplicate spaces.\\nAs a trainingcoordinator, I want to have an admin view that helps track registration status for each attendee so that, so that we can see if attendend, refunded, no show.\\nAs a attendee, I want to be added to a training waitlist, so that so they can be considered for a class.\\nAs a trainee, I want to must accept the cancellation terms with a checkbox, so that they can be accountable..\"}, {'rank': 2, 'score': 0.27285051345825195, 'source': 'g10-scrumalliance.txt', 'text': 'As a member, I want to have the system email me a new password or a password reminder since i have short-term memory problems.\\nAs a trainer, I want to read information of relevance only to trainers, so that the Scrum Alliance can share information with me easily.\\nAs a site editor, I want to post information in a trainers-only section, so that only trainers see it.'}, {'rank': 3, 'score': 0.265993595123291, 'source': 'g13-planningpoker.txt', 'text': \"As a moderator, I want to delete my account, so that account information and games are no longer stored.\\nAs a moderator, I want to see dates and times in my local timezone, so that I don't have to do timezone conversion myself.\\nAs a moderator, I want to get a password reminder by email, so that I can get back to using the application when I've forgotten my password.\\nAs a moderator, I want to select whether to have the team estimate with {0, 1/2, 1, 2, 3, 5, 8, etc.} or {0, 1, 2, 4, 8, 16, 32, etc.}, so that the team can use either the modified Fibonacci sequence or powers of 2.\\nAs a moderator, I want to invite up to 15 estimators, so that we can play with large but not immense teams.\\nAs an estimator, I want to join a game by entering my name on the page I received the URL for, so that I can participate.\\nAs an estimator, I want to see the item were estimating, so that I know what Im giving an estimate for.\\nAs an estimator, I want to see all items we will try to estimate this session, so that I have a feel for the sizes of the various items.\"}, {'rank': 4, 'score': 0.2633841335773468, 'source': 'g10-scrumalliance.txt', 'text': \"As a site member, I want to view the profiles of other members, so that I can find others I might want to connect with.\\nAs a site member, I want to search for profiles based on a few fields, so that I can find others I might want to connect with.\\nAs a site member, I want to mark my profile as private in which case only my name will appear, so that no one can learn things about me I don't want shared.\\nAs a site member, I want to mark my email address as private even if the rest of my profile is not, so that no one can contact me.\\nAs a site member, I want to send an email to any member via a form, so that we can connect.\\nAs a site administrator, I want to read practicing and training applications and approve or reject them, so that only applicants who qualify can become CSPs or CSTs.\\nAs a site administrator, I want to edit any site member profile, so that I can correct problems for members.\\nAs a site visitor, I want to read current news on the home page, so that I stay current on agile news.\\nAs a site visitor, I want to access old news that is no longer on the home page, so that I can access things I remember from the past or that others mention to me.\"}, {'rank': 5, 'score': 0.24156439304351807, 'source': 'g03-loudoun.txt', 'text': 'As a Public User, I want to Search for Information, so that I can obtain publicly available information concerning properties, County services, processes and other general information.\\nAs a ProspectiveApplicant, I want to research requirements and to select a service, so that I can find the relevant service and/or application type to initiate via the online portal.\\nAs an Applicant, I want to Request PreApplication Assistance, so that I can receive a response to a request for a meeting or information that is a result of the preapplication assistance.\\nAs a Customer, I want to Create a Customer Portal User Account, so that I can log on to the Customer Portal and perform transactions that first require user authentication.\\nAs an Applicant, I want to Submit Application, so that I can provide my information, plans and/or documents to initiate a transaction with the County.\\nAs an Applicant, I want to Submit Supporting Documentation, so that I can satisfy documentation requirements for my application.\\nAs an Applicant, I want to Pay Fee, so that I can satisfy outstanding charge associated with the service requested or received from the County.'}, {'rank': 6, 'score': 0.22948722541332245, 'source': 'g27-culrepo.txt', 'text': 'As a patron, I want to download report/dataset release calendar to load into own calendar.\\nAs a librarydiscoveryoperator, I want to harvest useful metadata from the repository via OAI, and continue to do so incrementally, so that I can make Cornell publications discoverable in my repository.\\nAs a library staff member, I want to quickly correct errors in uploaded metadata, and even uploaded documents, while leaving a record of my revisions (and possibly the reasons behind them), so that I can present correct versions of content and to locate points of error.\\nAs a library staff member, I want to receive a quick response and a reasonable resolution to tech support issues, so that service can proceed with minimal interruption.\\nAs a Cornell faculty member, I want to share on the repository files that are larger than 1GB in a way that still allows users to download them if I want to use them, so that I can meet funder requirements.\\nAs a DB/IR administrator, I want to login to personal account with access to authorized functions.\\nAs a DB/IR administrator, I want to have a personal account with the ability to change passwords to make them more secure or to retrieve forgotten ones.'}, {'rank': 7, 'score': 0.22693893313407898, 'source': 'g04-recycling.txt', 'text': 'As a user, I want to click on the address, so that it takes me to a new tab with Google Maps.\\nAs a user, I want to be able to anonymously view public information, so that I know about recycling centers near me before creating an account.\\nAs a user, I want to be able to enter my zip code and get a list of nearby recycling facilities, so that I can determine which ones I should consider.\\nAs a user, I want to be able to get the hours of each recycling facility, so that I can arrange drop-offs on my off days or during after-work hours.\\nAs a user, I want to have a flexible pick up time, so that I can more conveniently use the website.\\nAs a user, I want to be able to select different types of recyclable waste, so I have and get a list of facilities that accept each type and their opening hours, so that I can find an optimal route and schedule.\\nAs a user, I want to add donation centers as favorites on my profile, so that I can view them later.\\nAs a user, I want to be able to give my email ID, so that I can receive notifications for new events as they are posted.\\nAs a user, I want to be able to view a map display of the public recycling bins around my area.'}, {'rank': 8, 'score': 0.2197645604610443, 'source': 'g26-racdam.txt', 'text': \"As an administrator, I want to assign rights to user groups or roles, so that I can control what users can and can't do.\\nAs an administrator, I want to allow users to log in using Active Directory credentials, so that I don't have to manage another set of usernames and passwords.\\nAs an administrator, I want to have researchers reset their own passwords, so that I don't have to send passwords in cleartext.\\nAs an administrator, I want to limit who can see certain metadata fields, so that I can show or hide things from display based on user groups.\"}, {'rank': 9, 'score': 0.21571552753448486, 'source': 'g02-federalspending.txt', 'text': 'As an agency user, I want to get File F in the correct format.\\nAs an Agency user, I want to better understand my file-level errors.\\nAs a Developer , I want to provide FABS groups that function under the FREC paradigm.\\nAs a tester, I want to ensure that FABS is deriving fields properly through a robust test file plus a follow up check.\\nAs an owner, I only want zero-padded fields, so that I can justify padding.\\nAs a Broker user, I want to submit records for individual recipients without receiving a DUNS error.\\nAs a user, I want more information about how many rows will be published prior to deciding whether to publish.\\nAs a Developer, I want to prevent duplicate transactions from being published and deal with the time gap between validation and the publishing decision.\\nAs a FABS user, I want to submit a citywide as a PPoPZIP and pass validations.\\nAs a Broker user, I want to have updated error codes that accurately reflect the logic and provide enough information, so that I can fix my submission.\\nAs an agency user, I want to leave off the last 4 digits of the ZIP without an error, so that I can complete my submissions.'}, {'rank': 10, 'score': 0.21467101573944092, 'source': 'g12-camperplus.txt', 'text': \"As a parent, I want to be able to create an account, so that I can sign up my kids for camp online.\\nAs a parent, I want to see which counselors are assigned to my kids, so that I can have peace of mind.\\nAs a parent, I want to be able to message my child's counselors, so that I can voice my concerns or check on my child's progress.\\nAs a parent, I want to be able to sign and submit consent forms online, so that I don't have to deal with my child losing a consent form.\\nAs a parent, I want to be able to see if I made all the necessary payments.\\nAs a parent, I want to be able to share any photos the camp has taken of my child.\\nAs a parent, I want to be able to connect with the staff in case of an emergency.\\nAs a parent, I want to be able to enroll my children, so that they can be admitted to camp.\\nAs a parent, I want to be able to see and edit my enrolled children to the camp year, so that I can know who I already enrolled to camp, who is still pending admission etc.\\nAs a parent, I want to be able to see a schedule of the activities my children are involved in at camp, so that I can be more informed as to what they are doing at camp.\"}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#trying it\n",
        "md_text, evidence = generate_test_cases(\n",
        "    \"User login: email verification, wrong credentials, password change\",\n",
        "    k=10, use=\"local\"\n",
        ")\n",
        "print(md_text[:1500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oI2XQS3K7iRS",
        "outputId": "3e3406ce-2d9b-4d9a-f21b-1ad283bdaf11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: 17 prefix-match hit, remaining 2577 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =   48945.95 ms\n",
            "llama_perf_context_print: prompt eval time =   47374.71 ms /  2577 tokens (   18.38 ms per token,    54.40 tokens per second)\n",
            "llama_perf_context_print:        eval time =   76186.71 ms /  1023 runs   (   74.47 ms per token,    13.43 tokens per second)\n",
            "llama_perf_context_print:       total time =  124550.12 ms /  3600 tokens\n",
            "llama_perf_context_print:    graphs reused =        990\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " - Feature: User Login\n",
            "- Scope: Email verification, wrong credentials, password change\n",
            "- Assumptions/Notes: The system allows users to register with a valid email address and create a password.\n",
            "\n",
            "- Test Cases (table):\n",
            "  | ID | Title | Type (pos/neg/edge) | Pre-Conditions | Steps | Expected Result | Priority (H/M/L) | MapsTo (AC id/phrase) |\n",
            "  | 1 | Valid Email and Correct Credentials | Positive | User is registered with a valid email and password | Enter valid email and password in login form | User is granted access to the system | High | As a user, I want to log in with valid email and password (g04-recycling.txt) |\n",
            "  | 2 | Valid Email and Incorrect Credentials | Negative | User is registered with a valid email and incorrect password | Enter valid email and incorrect password in login form | User is not granted access to the system | Medium | As a user, I want to log in with incorrect credentials (g04-recycling.txt) |\n",
            "  | 3 | Invalid Email and Correct Credentials | Negative | User enters an invalid email address | Enter an invalid email address and correct password in login form | User is not granted access to the system | Medium | As a user, I want to enter an invalid email address (g04-recycling.txt) |\n",
            "  | 4 | Invalid Email and Incorrect Credentials | Negative | User enters an invalid email address and incorrect password | Enter an invalid email address and incorrect password in login form | User is not granted access to the system | Low | As a user, I want to enter an inv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(evidence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abfLOUAwPH-P",
        "outputId": "00395d1d-7859-406d-fec2-5349a9b727f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'rank': 1, 'score': 0.2052965611219406, 'source': 'g04-recycling.txt', 'text': \"As a user, I want to view all locations of recycling centers on a map, so that I can check which routes to take to drop off waste.\\nAs a user, I want to upload my week's schedule, so that I can get recommendations for recycling centers that best fit my availability.\\nAs a user, I want to link my email account to my profile, so that I can get a temporary password in case I forget my own one.\\nAs a user, I want to contact the administrators, so that I can give feedback or ask for help.\\nAs an admin, I want to add recycling center information, so that I can keep the database up-to-date over time.\\nAs an admin, I want to view user error logs, so that I can fix or review any issues that are being faced by users of the system.\\nAs an admin, I want to onboard recycling centers on the platform, so that I can increase information accuracy.\\nAs a superuser, I want to update the recycling center information, so that I can provide the latest information about the recycling center.\\nAs a superuser, I want to view users' stats, so that I can view in real-time how many users have visited my recycling center information and their recyclable waste.\"}, {'rank': 2, 'score': 0.1953386664390564, 'source': 'g13-planningpoker.txt', 'text': \"As a moderator, I want to delete my account, so that account information and games are no longer stored.\\nAs a moderator, I want to see dates and times in my local timezone, so that I don't have to do timezone conversion myself.\\nAs a moderator, I want to get a password reminder by email, so that I can get back to using the application when I've forgotten my password.\\nAs a moderator, I want to select whether to have the team estimate with {0, 1/2, 1, 2, 3, 5, 8, etc.} or {0, 1, 2, 4, 8, 16, 32, etc.}, so that the team can use either the modified Fibonacci sequence or powers of 2.\\nAs a moderator, I want to invite up to 15 estimators, so that we can play with large but not immense teams.\\nAs an estimator, I want to join a game by entering my name on the page I received the URL for, so that I can participate.\\nAs an estimator, I want to see the item were estimating, so that I know what Im giving an estimate for.\\nAs an estimator, I want to see all items we will try to estimate this session, so that I have a feel for the sizes of the various items.\"}, {'rank': 3, 'score': 0.19398869574069977, 'source': 'g10-scrumalliance.txt', 'text': 'As a member, I want to have the system email me a new password or a password reminder since i have short-term memory problems.\\nAs a trainer, I want to read information of relevance only to trainers, so that the Scrum Alliance can share information with me easily.\\nAs a site editor, I want to post information in a trainers-only section, so that only trainers see it.'}, {'rank': 4, 'score': 0.19129037857055664, 'source': 'g26-racdam.txt', 'text': \"As an administrator, I want to assign rights to user groups or roles, so that I can control what users can and can't do.\\nAs an administrator, I want to allow users to log in using Active Directory credentials, so that I don't have to manage another set of usernames and passwords.\\nAs an administrator, I want to have researchers reset their own passwords, so that I don't have to send passwords in cleartext.\\nAs an administrator, I want to limit who can see certain metadata fields, so that I can show or hide things from display based on user groups.\"}, {'rank': 5, 'score': 0.16604097187519073, 'source': 'g27-culrepo.txt', 'text': 'As a patron, I want to download report/dataset release calendar to load into own calendar.\\nAs a librarydiscoveryoperator, I want to harvest useful metadata from the repository via OAI, and continue to do so incrementally, so that I can make Cornell publications discoverable in my repository.\\nAs a library staff member, I want to quickly correct errors in uploaded metadata, and even uploaded documents, while leaving a record of my revisions (and possibly the reasons behind them), so that I can present correct versions of content and to locate points of error.\\nAs a library staff member, I want to receive a quick response and a reasonable resolution to tech support issues, so that service can proceed with minimal interruption.\\nAs a Cornell faculty member, I want to share on the repository files that are larger than 1GB in a way that still allows users to download them if I want to use them, so that I can meet funder requirements.\\nAs a DB/IR administrator, I want to login to personal account with access to authorized functions.\\nAs a DB/IR administrator, I want to have a personal account with the ability to change passwords to make them more secure or to retrieve forgotten ones.'}, {'rank': 6, 'score': 0.14705632627010345, 'source': 'g14-datahub.txt', 'text': \"As a Consumer, I want to see a publisher's profile, so that that I can discover their packages and get a sense of how active and good they are.\\nAs a Consumer, I want to view a publisher's profile, so that that I can see who is behind a particular package or to see what other packages they produce. \\nAs a Consumer, I want to search among all data packages owned by a publisher, so that that I can easily find one data package amongst all the data packages by this publisher.\\nAs an Owner, I want to edit my profile, so that that it is updated with new information.\\nAs an Owner, I want to invite an existing user, so that the user can become a member of my publisher.\\nAs an owner, I want to invite someone using their email to sign up and become a member of my Publisher, so that that they are authorized to publish data packages under my Publisher.\\nAs an owner, I want to remove someone from membership in my publisher, so that they no longer have ability to publish or modify my data packages.\\nAs an owner, I want to view all the people in my organization and what roles they have, so that that I can change these if I want.\"}, {'rank': 7, 'score': 0.14117363095283508, 'source': 'g03-loudoun.txt', 'text': 'As a Plan Review Staff member, I want to Assign Plans for Review, so that I can ensure plans have been assigned to the appropriate Plan Reviewer.\\nAs a Plan Review Staff Supervisor, I want to Manage Plan Reviewer Workload, so that I can monitor and effectively adjust workload as necessary and ensure service levels are met\\nAs an Applicant, I want to Request a Plan Review Meeting, so that I can meet with the Plan Review Staff regarding the plan review.\\nAs a Plan Review Staff member, I want to successfully Conduct a Plan Review Meeting with the Applicant and record the outcome, so that I can listen to it again.\\nAs a Plan Review Staff member, I want to Review Plans, so that I can review them for compliance and either approve, or fail or deny the plans and record any conditions, clearances, or corrections needed from the Applicant.\\nAs an Applicant, I want to Resubmit Plans, so that I can review revised plans. \\nAs a Plan Review Staff Member, I want to Review the Code Modifications submitted by the Applicant, so that I can review the request and if approved, associate it with the appropriate project.'}, {'rank': 8, 'score': 0.14067289233207703, 'source': 'g10-scrumalliance.txt', 'text': \"As a site member, I want to view the profiles of other members, so that I can find others I might want to connect with.\\nAs a site member, I want to search for profiles based on a few fields, so that I can find others I might want to connect with.\\nAs a site member, I want to mark my profile as private in which case only my name will appear, so that no one can learn things about me I don't want shared.\\nAs a site member, I want to mark my email address as private even if the rest of my profile is not, so that no one can contact me.\\nAs a site member, I want to send an email to any member via a form, so that we can connect.\\nAs a site administrator, I want to read practicing and training applications and approve or reject them, so that only applicants who qualify can become CSPs or CSTs.\\nAs a site administrator, I want to edit any site member profile, so that I can correct problems for members.\\nAs a site visitor, I want to read current news on the home page, so that I stay current on agile news.\\nAs a site visitor, I want to access old news that is no longer on the home page, so that I can access things I remember from the past or that others mention to me.\"}, {'rank': 9, 'score': 0.140463724732399, 'source': 'g12-camperplus.txt', 'text': \"As a parent, I want to be able to create an account, so that I can sign up my kids for camp online.\\nAs a parent, I want to see which counselors are assigned to my kids, so that I can have peace of mind.\\nAs a parent, I want to be able to message my child's counselors, so that I can voice my concerns or check on my child's progress.\\nAs a parent, I want to be able to sign and submit consent forms online, so that I don't have to deal with my child losing a consent form.\\nAs a parent, I want to be able to see if I made all the necessary payments.\\nAs a parent, I want to be able to share any photos the camp has taken of my child.\\nAs a parent, I want to be able to connect with the staff in case of an emergency.\\nAs a parent, I want to be able to enroll my children, so that they can be admitted to camp.\\nAs a parent, I want to be able to see and edit my enrolled children to the camp year, so that I can know who I already enrolled to camp, who is still pending admission etc.\\nAs a parent, I want to be able to see a schedule of the activities my children are involved in at camp, so that I can be more informed as to what they are doing at camp.\"}, {'rank': 10, 'score': 0.13765698671340942, 'source': 'g21-badcamp.txt', 'text': 'As a anonymoususer, I want to register to speak at BADCamp, so that I submit a session.\\nAs a authenticateduser, I want to submit a session at BADCAMP, so that I can get my session evaluated.\\nAs a sponsor, I want to personalize my sponsorship page, so that I can promote my brand.\\nAs a anonymoususer, I want to see a list of all the summits that include when they are, so that I can determine which summit I want to attend.\\nAs a authenticateduser, I want to Be offered several choices of idividual sponsorship on the second page of registration, so that I can be awesome and financially support the camp.\\nAs a anonymoususer, I want to easily find a link in the menu that links to the registration form, so that I can easily register for the camp.\\nAs a anonymoususer, I want to fill out a user registration form, so that I can register for the camp and get an account on the website.\\nAs a anonymoususer, I want to find session information, so that I can go to a session.'}]\n"
          ]
        }
      ]
    }
  ]
}